### 基本概念
非线性表数据结构 
- 树、节点、父子关系、父节点、子节点、兄弟节点、根节点、叶节点
- 高度、深度、层

### 二叉树 
- 每个节点**最多**两个子节点，分别是左子节点和右子节点。
- 满二叉树：叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点
- 完全二叉树：最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大
    - 要理解完全二叉树定义的由来，我们需要先了解，如何表示（或者存储）一棵二叉树？
        - 链式存储法：每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。
        - 顺序存储法：把根节点存储在下标 `i = 1` 的位置，那左子节点存储在下标 `2 * i = 2` 的位置，右子节点存储在 `2 * i + 1 = 3` 的位置，以此类推，只要知道根节点存储的位置，这样就可以通过下标计算，把整棵树都串起来。
            - 如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式
- 堆和堆排序，堆其实就是一种完全二叉树，最常用的存储方式就是数组。   

### 二叉树的遍历 
         
- 前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
- 中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
- 后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。
```
def preorder(root):
    if root:
        action on root
        preorder(root.left)
        preorder(root.right)
```

### 二叉查找树（Binary Search Tree）
- 支持动态数据集合的快速插入、删除、查找操作。    
- 二叉查找树要求，在树中的任意一个节点，其左子树中的**所有**节点的值，都要小于这个节点的值，而右子树**所有**节点的值都大于这个节点的值。    
    - 查找：要查找的数据比根节点小，则在左子树递归查找；比根节点大，则在右子树递归查找
    ```python
    def find(root, data):
        p = root
        while p:
            if data < p.val:
                p = p.left
            elif data > p.val:
                p = p.right
            else:
                return p
        return
    ```    
    - 插入：新插入的数据一般都在叶子节点上；要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。
    ```python
    def insert(root, data):
        if not root:
            root = Node(data)
            return root
        p = root
        while p:
            if data > p.val:
                if not p.right:
                    p.right = Node(data)
                    return
                p = p.right
            else:
                if not p.left:
                    p.left = Node(data)
                    return
                p = p.left
    ```
    - 删除：
        1. 如果要删除的节点C没有子节点，将该节点的父节点P指向该节点C的指针置为 None
        2. 要删除的节点C，只有一个子节点S，将该节点的父节点P指向该节点C的指针置为子节点S
        3. 要删除的节点C有两个子节点，找到其右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点
    ```python
    def delete(root, data):
        # 找到该节点，记录该节点及其父节点
        p = root
        pp = None
        while p and p.val != data:
            pp = p
            if data > p.val:
                p = p.right
            else:
                p = p.left
        if not p:
            return None
        
        # 该节点有两个子节点，找到右子树的最小节点及其父节点
        if p.left and p.right:
            minP = p.right
            minPP = p
            while minP.left:
                minPP = minP
                minP = minP.left
        
            p.val = minP.val
            p = minP
            pp = minPP
    
        # 该节点是叶子节点或仅有一个子节点
        if p.left:
            child = p.left
        elif p.right:
            child = p.right
        else:
            child = None
        
        # 删除根节点
        if not pp:
            root = child
        elif pp.left == p:
            pp.left = child
        else:
            pp.right = child      
    ```        
  
- 通常在二叉查找树中存储的，是一个包含很多字段的对象。利用对象的某个字段作为键值（key）来构建二叉查找树。而把对象中的其他字段叫作卫星数据。
- 当两个对象键值相同时：
    - 把值相同的数据都存储在同一个节点上
    - 在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，就将这个要插入的数据放到这个节点的右子树；
        - 当要查找数据的时候，遇到值相同的节点，并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止
        - 对于删除操作，我们也需要先查找到每个要删除的节点，然后再按前面讲的删除操作的方法，依次删除。
        
- 时间复杂度：不管操作是插入、删除还是查找，时间复杂度都跟树的高度成正比，也就是 O(height)
    - 对于完全二叉树，height的范围是 $log_2(n+1), log_2n+1$

### 对比散列表
- 散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效；而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)
- 但是：
    - 散列表中数据是无序储存的，，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
    - 散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定
    - 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。

           